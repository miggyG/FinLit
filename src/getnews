# 3 array of everything 2 ticker scores only
from urllib.request import urlopen, Request
from bs4 import BeautifulSoup
from nltk.sentiment.vader import SentimentIntensityAnalyzer
finviz_url = 'https://finviz.com/quote.ashx?t='
news_tables = {}
vader = SentimentIntensityAnalyzer()
tickerscores = {}
parsed_data = []


def mainsia(tickers, returntype):
    for ticker in tickers:
        url = finviz_url + ticker

        req = Request(url=url, headers={'user-agent': 'my-app'})
        try:
            response = urlopen(req)

            html = BeautifulSoup(response, features='html.parser')
            news_table = html.find(id='news-table')
            news_tables[ticker] = news_table

        except:
            pass

    for ticker, news_table in news_tables.items():
        scorec = []
        try:
            for row in news_table.findAll('tr'):
                try:
                    title = row.a.text
                    date_data = row.td.text.split(' ')
                    score = vader.polarity_scores(title)
                    scorec.append(score['compound'])
                    if len(date_data) == 1:
                        time = date_data[0]
                        parsed_data.append([ticker, time, title, scorec])
                    else:
                        date = date_data[0]
                        time = date_data[1]
                        parsed_data.append([ticker, date, time, title, scorec])

                except:
                    pass
        except:
            pass
        tickerscores[ticker] = sum(scorec)/100

    if returntype == 3:
        return parsed_data
    elif returntype == 2:
        return tickerscores
    else:
        return tickerscores
